Untitled.ipynb:    "    print(gt)\n",
Untitled.ipynb:    "    print(gt)\n",
demo.py:            print("Can not read image in Frame : {}".format(index))
demo.py:    print("Post-process time", total_time / (index+1))
demo.py:        print("Images saved to", output_path)
demo.py:    print('Warmup the detector...')
demo.py:                print('In {}\{}, total time: {} \n preprocess: {} \n net_forward: {} \n detect: {} \n output: {}'.format(
demo.py:    print('In average, total time: {}ms \n preprocess: {}ms \n net_forward: {}ms \n detect: {}ms \n output: {}ms'.format(
lib/dataset/cones.py:                print('test set will not load annotations!')
lib/dataset/cones.py:#            print('{} gt roidb loaded from {}'.format(coco_name,cache_file))
lib/dataset/cones.py:#        print('parsing gt roidb for {}'.format(coco_name))
lib/dataset/cones.py:#        print('wrote gt roidb to {}'.format(cache_file))
lib/dataset/cones.py:#            print('{} img path loaded from {}'.format(coco_name,cache_file))
lib/dataset/cones.py:#        print('parsing img path for {}'.format(coco_name))
lib/dataset/cones.py:#        print('wrote img path to {}'.format(cache_file))
lib/dataset/voc_eval.py:                print('Reading annotation for {:d}/{:d}'.format(
lib/dataset/voc_eval.py:        print('Saving cached annotations to {:s}'.format(cachefile))
lib/dataset/coco.py:                print('test set will not load annotations!')
lib/dataset/coco.py:            print('{} gt roidb loaded from {}'.format(coco_name,cache_file))
lib/dataset/coco.py:        print('parsing gt roidb for {}'.format(coco_name))
lib/dataset/coco.py:        print('wrote gt roidb to {}'.format(cache_file))
lib/dataset/coco.py:            print('{} img path loaded from {}'.format(coco_name,cache_file))
lib/dataset/coco.py:        print('parsing img path for {}'.format(coco_name))
lib/dataset/coco.py:        print('wrote img path to {}'.format(cache_file))
lib/dataset/coco.py:        #print(target.shape)
lib/dataset/coco.py:        print('~~~~ Mean and per-category AP @ IoU=[{:.2f},{:.2f}] '
lib/dataset/coco.py:        print('{:.1f}'.format(100 * ap_default))
lib/dataset/coco.py:            print('{:.1f}'.format(100 * ap))
lib/dataset/coco.py:        print('~~~~ Summary metrics ~~~~')
lib/dataset/coco.py:        print('Wrote COCO eval results to: {}'.format(eval_file))
lib/dataset/coco.py:            print('Collecting {} results ({:d}/{:d})'.format(cls, cls_ind,
lib/dataset/coco.py:                print('Writing results json to {}'.format(res_f))
lib/dataset/coco.py:        print('Writing results json to {}'.format(res_file))
lib/dataset/voc.py:            #print(img.size())
lib/dataset/voc.py:        #print(target.shape)
lib/dataset/voc.py:            print('Writing {} VOC results file'.format(cls))
lib/dataset/voc.py:        print('VOC07 metric? ' + ('Yes' if use_07_metric else 'No'))
lib/dataset/voc.py:            print('AP for {} = {:.4f}'.format(cls, ap))
lib/dataset/voc.py:        print('Mean AP = {:.4f}'.format(np.mean(aps)))
lib/dataset/voc.py:        print('~~~~~~~~')
lib/dataset/voc.py:        print('Results:')
lib/dataset/voc.py:            print('{:.3f}'.format(ap))
lib/dataset/voc.py:        print('{:.3f}'.format(np.mean(aps)))
lib/dataset/voc.py:        print('~~~~~~~~')
lib/dataset/voc.py:        print('')
lib/dataset/voc.py:        print('--------------------------------------------------------------')
lib/dataset/voc.py:        print('Results computed with the **unofficial** Python eval code.')
lib/dataset/voc.py:        print('Results should be very close to the official MATLAB eval code.')
lib/dataset/voc.py:        print('Recompute with `./tools/reval.py --matlab ...` for your paper.')
lib/dataset/voc.py:        print('-- Thanks, The Management')
lib/dataset/voc.py:        print('--------------------------------------------------------------')
lib/dataset/voc.py:#     print(len(ds))
lib/dataset/voc.py:#     print(target)
lib/utils/dark2pth.py:    print('layer     filters    size              input                output');
lib/utils/dark2pth.py:            print('%5d %-6s %4d  %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'conv', filters, kernel_size, kernel_size, stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:            print('%5d %-6s       %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'max', pool_size, pool_size, stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:            print('%5d %-6s                   %3d x %3d x%4d   ->  %3d' % (ind, 'avg', prev_width, prev_height, prev_filters,  prev_filters))
lib/utils/dark2pth.py:            print('%5d %-6s                                    ->  %3d' % (ind, 'softmax', prev_filters))
lib/utils/dark2pth.py:            print('%5d %-6s                                     ->  %3d' % (ind, 'cost', prev_filters))
lib/utils/dark2pth.py:            print('%5d %-6s             / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'reorg', stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:                print('%5d %-6s %d' % (ind, 'route', layers[0]))
lib/utils/dark2pth.py:                print('%5d %-6s %d %d' % (ind, 'route', layers[0], layers[1]))
lib/utils/dark2pth.py:            print('%5d %-6s' % (ind, 'detection'))
lib/utils/dark2pth.py:            print('%5d %-6s' % (ind, 'yolo'))
lib/utils/dark2pth.py:            print('%5d %-6s           / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'upsample', stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:            print('%5d %-6s %d' % (ind, 'shortcut', from_id))
lib/utils/dark2pth.py:            print('%5d %-6s                            %d  ->  %3d' % (ind, 'connected', prev_filters,  filters))
lib/utils/dark2pth.py:            print('unknown type %s' % (block['type']))
lib/utils/dark2pth.py:    print('layer     filters    size              input                output')
lib/utils/dark2pth.py:            print('%5d %-6s %4d  %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'conv', filters, kernel_size, kernel_size, stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:                print(model_index, model[model_index].conv[model_sub*3])
lib/utils/dark2pth.py:            print('%5d %-6s       %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'max', pool_size, pool_size, stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:            print('%5d %-6s                   %3d x %3d x%4d   ->  %3d' % (ind, 'avg', prev_width, prev_height, prev_filters,  prev_filters))
lib/utils/dark2pth.py:            print('%5d %-6s                                    ->  %3d' % (ind, 'softmax', prev_filters))
lib/utils/dark2pth.py:            print('%5d %-6s                                     ->  %3d' % (ind, 'cost', prev_filters))
lib/utils/dark2pth.py:            print('%5d %-6s             / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'reorg', stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:                print('%5d %-6s %d' % (ind, 'route', layers[0]))
lib/utils/dark2pth.py:                print('%5d %-6s %d %d' % (ind, 'route', layers[0], layers[1]))
lib/utils/dark2pth.py:            print('%5d %-6s' % (ind, 'detection'))
lib/utils/dark2pth.py:            print('%5d %-6s' % (ind, 'yolo'))
lib/utils/dark2pth.py:            print('%5d %-6s           / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'upsample', stride, prev_width, prev_height, prev_filters, width, height, filters))
lib/utils/dark2pth.py:            print('%5d %-6s %d' % (ind, 'shortcut', from_id))
lib/utils/dark2pth.py:            print('%5d %-6s                            %d  ->  %3d' % (ind, 'connected', prev_filters,  filters))
lib/utils/dark2pth.py:            print('unknown type %s' % (block['type']))
lib/utils/dark2pth.py:    print('convert yolov2...')
lib/utils/dark2pth.py:    # print(yolo_v2.base[0].conv[1].bias)
lib/utils/dark2pth.py:    # print(yolo_v2.loc[0].weight)
lib/utils/dark2pth.py:    # print(yolo_v2.base[0].conv[1].bias)
lib/utils/dark2pth.py:    # print(yolo_v2.loc[0].weight)
lib/utils/dark2pth.py:    print('convert yolov3...')
lib/utils/config_parse.py:#         print(('Error under config key: {}'.format(k)))
lib/utils/data_augment.py:            # print('image adding')
lib/utils/nms/build.py:    print('Including CUDA code.')
lib/utils/nms/build.py:print(this_file)
lib/utils/nms/build.py:print(extra_objects)
lib/utils/eval_utils.py:        # print(ground_turths)
lib/utils/eval_utils.py:        # print('gt', gt)
lib/utils/eval_utils.py:        # print(detect)
lib/utils/eval_utils.py:        # print('gt', gt)
lib/utils/eval_utils.py:        # print(inter_max)
lib/utils/eval_utils.py:        # print(inter_min)
lib/utils/eval_utils.py:        # print(inter_size)
lib/utils/eval_utils.py:        # print(det_size, gt_size)
lib/utils/eval_utils.py:        # print(iou)
lib/utils/eval_utils.py:#             # print(det_c)
lib/ssds_validation.py.save:        print('===> Building model')
lib/ssds_validation.py.save:            print('Utilize GPUs for computation')
lib/ssds_validation.py.save:            print('Number of GPU available', torch.cuda.device_count())
lib/ssds_validation.py.save:        print('Model architectures:\n{}\n'.format(self.model))
lib/ssds_validation.py.save:        # print('Parameters and size:')
lib/ssds_validation.py.save:        #     print('{}: {}'.format(name, list(param.size())))
lib/ssds_validation.py.save:        print('Trainable scope: {}'.format(cfg.TRAIN.TRAINABLE_SCOPE))
lib/ssds_validation.py.save:        print('===> Loading data')
lib/ssds_validation.py.save:        print('Wrote snapshot to: {:s}'.format(filename))
lib/ssds_validation.py.save:            print(("=> no checkpoint found at '{}'".format(resume_checkpoint)))
lib/ssds_validation.py.save:        print(("=> loading checkpoint '{:s}'".format(resume_checkpoint)))
lib/ssds_validation.py.save:        # print("=> Weigths in the checkpoints:")
lib/ssds_validation.py.save:        # print([k for k, v in list(checkpoint.items())])
lib/ssds_validation.py.save:        # print("=> Resume weigths:")
lib/ssds_validation.py.save:        # print([k for k, v in list(pretrained_dict.items())])
lib/ssds_validation.py.save:            print("=> UNResume weigths:")
lib/ssds_validation.py.save:            print(unresume_dict)
lib/ssds_validation.py.save:            print('Loading initial model weights from {:s}'.format(self.checkpoint))
lib/ssds_validation.py.save:                # print(getattr(self.model, module))
lib/ssds_train.py:        # print("=> Weigths in the checkpoints:")
lib/ssds_train.py:        # print([k for k, v in list(checkpoint.items())])
lib/ssds_train.py:        # print("=> Resume weigths:")
lib/ssds_train.py:        # print([k for k, v in list(pretrained_dict.items())])
lib/ssds_train.py:                # print(getattr(self.model, module))
lib/modeling/ssds/fssd_lite.py:        # print(self.base)
lib/modeling/ssds/fssd_lite.py:        # print(self.extras)
lib/modeling/ssds/fssd_lite.py:        # print(self.loc)
lib/modeling/ssds/yolo.py:    # # print('yolo_v2', yolo_v2)
lib/modeling/ssds/yolo.py:    # print([(o.size()[2], o.size()[3]) for o in feature_maps])
lib/modeling/ssds/yolo.py:    print('yolo_v3', yolo_v3)
lib/modeling/ssds/yolo.py:    # print(yolo_v3.feature_layer, yolo_v3.feature_index)
lib/modeling/ssds/yolo.py:    # print([(o.size()[2], o.size()[3]) for o in feature_maps])
lib/modeling/ssds/yolo.py:    # print(set(yolo_v3.state_dict()))
lib/modeling/ssds/yolo.py:    print(set(yolo_v3.base[0].conv[1].state_dict()))
lib/modeling/model_builder.py:    print('==>Model blocks:')
lib/modeling/model_builder.py:    print(model)
lib/modeling/model_builder.py:    print('==>Feature map size:')
lib/modeling/model_builder.py:    print(feature_maps)
lib/layers/functions/prior_box.py:        #     print(f, self.aspect_ratios[k])
lib/layers/functions/detection.py:        # print(nms_time, cpu_tims, scores_time,box_time,gpunms_time)
lib/ssds_validation.py.save.1:        print('===> Building model')
lib/ssds_validation.py.save.1:            print('Utilize GPUs for computation')
lib/ssds_validation.py.save.1:            print('Number of GPU available', torch.cuda.device_count())
lib/ssds_validation.py.save.1:        print('Model architectures:\n{}\n'.format(self.model))
lib/ssds_validation.py.save.1:        # print('Parameters and size:')
lib/ssds_validation.py.save.1:        #     print('{}: {}'.format(name, list(param.size())))
lib/ssds_validation.py.save.1:        print('Trainable scope: {}'.format(cfg.TRAIN.TRAINABLE_SCOPE))
lib/ssds_validation.py.save.1:        print('===> Loading data')
lib/ssds_validation.py.save.1:        print('Wrote snapshot to: {:s}'.format(filename))
lib/ssds_validation.py.save.1:            print(("=> no checkpoint found at '{}'".format(resume_checkpoint)))
lib/ssds_validation.py.save.1:        print(("=> loading checkpoint '{:s}'".format(resume_checkpoint)))
lib/ssds_validation.py.save.1:        # print("=> Weigths in the checkpoints:")
lib/ssds_validation.py.save.1:        # print([k for k, v in list(checkpoint.items())])
lib/ssds_validation.py.save.1:        # print("=> Resume weigths:")
lib/ssds_validation.py.save.1:        # print([k for k, v in list(pretrained_dict.items())])
lib/ssds_validation.py.save.1:            print("=> UNResume weigths:")
lib/ssds_validation.py.save.1:            print(unresume_dict)
lib/ssds_validation.py.save.1:            print('Loading initial model weights from {:s}'.format(self.checkpoint))
lib/ssds_validation.py.save.1:                # print(getattr(self.model, module))
lib/ssds_validation.py.save.1:        print(eval_stats)
lib/ssds_validation.py.save.1:            print("FOLD", val_set_index)
lib/ssds_validation.py.save.1:            print("Using ", fold_cfg.DATASET.TEST_SETS, "as validation set")
lib/ssds_validation.py.save.1:            print("FOLD FINISHED")
lib/ssds_validation.py.save.1:            print("prec: {} rec: {} ap: {}".format(prec, rec, ap))
lib/ssds_validation.py.save.1:        print("KFOLD VALIDATION FINISHED")
lib/ssds_validation.py.save.1:        print("FINAL STATS")
lib/ssds_validation.py.save.1:        print("prec: {} rec: {} ap: {}".format(eval_stats[0], eval_stats[1], eval_stats[2]))
lib/ssds_validation.py.save.1:    #     print('Evaluating detections')
lib/ssds_validation.py.save.1:        print('Evaluating detections')
lib/ssds_validation.py:        print('===> Building model')
lib/ssds_validation.py:            print('Utilize GPUs for computation')
lib/ssds_validation.py:            print('Number of GPU available', torch.cuda.device_count())
lib/ssds_validation.py:        print('Model architectures:\n{}\n'.format(self.model))
lib/ssds_validation.py:        # print('Parameters and size:')
lib/ssds_validation.py:        #     print('{}: {}'.format(name, list(param.size())))
lib/ssds_validation.py:        print('Trainable scope: {}'.format(cfg.TRAIN.TRAINABLE_SCOPE))
lib/ssds_validation.py:        print('===> Loading data')
lib/ssds_validation.py:        print('Wrote snapshot to: {:s}'.format(filename))
lib/ssds_validation.py:            print(("=> no checkpoint found at '{}'".format(resume_checkpoint)))
lib/ssds_validation.py:        print(("=> loading checkpoint '{:s}'".format(resume_checkpoint)))
lib/ssds_validation.py:        # print("=> Weigths in the checkpoints:")
lib/ssds_validation.py:        # print([k for k, v in list(checkpoint.items())])
lib/ssds_validation.py:        # print("=> Resume weigths:")
lib/ssds_validation.py:        # print([k for k, v in list(pretrained_dict.items())])
lib/ssds_validation.py:            print("=> UNResume weigths:")
lib/ssds_validation.py:            print(unresume_dict)
lib/ssds_validation.py:            print('Loading initial model weights from {:s}'.format(self.checkpoint))
lib/ssds_validation.py:                # print(getattr(self.model, module))
lib/ssds_validation.py:        print(eval_stats)
lib/ssds_validation.py:            print("FOLD", val_set_index)
lib/ssds_validation.py:            print("Using ", fold_cfg.DATASET.TEST_SETS, "as validation set")
lib/ssds_validation.py:            print("FOLD FINISHED")
lib/ssds_validation.py:            print("prec: {} rec: {} ap: {}".format(prec, rec, ap))
lib/ssds_validation.py:        print("KFOLD VALIDATION FINISHED")
lib/ssds_validation.py:        print("FINAL STATS")
lib/ssds_validation.py:        print("prec: {} rec: {} ap: {}".format(eval_stats[0], eval_stats[1], eval_stats[2]))
lib/ssds_validation.py:    #     print('Evaluating detections')
lib/ssds_validation.py:        print('Evaluating detections')
nms_locations.txt:print_locations.txt:lib/utils/nms/build.py:    print('Including CUDA code.')
nms_locations.txt:print_locations.txt:lib/utils/nms/build.py:print(this_file)
nms_locations.txt:print_locations.txt:lib/utils/nms/build.py:print(extra_objects)
nms_locations.txt:print_locations.txt:lib/layers/functions/detection.py:        # print(nms_time, cpu_tims, scores_time,box_time,gpunms_time)
nms_locations.txt:lib/layers/functions/detection.py:        # print(nms_time, cpu_tims, scores_time,box_time,gpunms_time)
